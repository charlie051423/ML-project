{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c66d527-f0f8-4cd2-84b0-c8ad51c917a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc572054-06f1-4da1-9fd7-83b7a447bfb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath2021=\"dbfs:/FileStore/output/resnet50v2_train_output.csv\"\n",
    "df_img_2021 = spark.read.format(\"csv\").option(\"mode\", \"DROPMALFORMED\").option(\"header\", \"true\").load(filepath2021)\n",
    "\n",
    "filepath2022=\"dbfs:/FileStore/output/resnet50v2_test_output.csv\"\n",
    "df_img_2022 = spark.read.format(\"csv\").option(\"mode\", \"DROPMALFORMED\").option(\"header\", \"true\").load(filepath2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6afa2e3b-00b5-4033-b742-f3bddde20be0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_img_2021 = df_img_2021.toPandas()\n",
    "df_img_2022 = df_img_2022.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d773396e-f5bc-4ec5-ae7e-d558725e4b22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = df_img_2021['pred'].apply(lambda x: x.split(','))\n",
    "temp2022 = df_img_2022['pred'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc05ceb-d0ec-424a-995f-0de39ab34ab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_img_2021['pred_cat'] = temp.apply(lambda x: x[1].replace(' ', '').replace(\"'\", ''))\n",
    "df_img_2022['pred_cat'] = temp2022.apply(lambda x: x[1].replace(' ', '').replace(\"'\", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43eeb4c0-041d-436a-9e77-568750eae820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "container =\"data1\"\n",
    "data_path = f\"abfss://{container}@capstone2023cuhk.dfs.core.windows.net/\"\n",
    "df = spark.read.csv(os.path.join(data_path, \"AML-data\", \"Actual_Data_2021-2022\", \"ITEM_MATCHING_2021_BOOKS.csv\"), header=True)\n",
    "df2 = spark.read.csv(os.path.join(data_path, \"AML-data\", \"Actual_Data_2021-2022\", \"ITEM_MATCHING_2022_BOOKS.csv\"), header=True)\n",
    "df = df.toPandas()\n",
    "df2 = df2.toPandas()\n",
    "df = df.loc[df['PRICE']!='0']\n",
    "df = df.loc[df['QTY_SALES']!='0']\n",
    "df2 = df2.loc[df2['PRICE']!='0']\n",
    "df2 = df2.loc[df2['QTY_SALES']!='0']\n",
    "# df.loc[df['QTY_SALES']=='MBI       ']\n",
    "df = df.drop(index=[583])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067c2751-211d-45d9-a6ce-30658c43b3cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['PRODUCT_ID'] = df['PRODUCT_ID'].str.strip()\n",
    "df2['PRODUCT_ID'] = df2['PRODUCT_ID'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65b4423-447a-45dc-97ec-b53e84343a22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.merge(df_img_2021, on=\"PRODUCT_ID\")\n",
    "df2 = df2.merge(df_img_2022, on=\"PRODUCT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb75054-36d4-429e-ba7e-231854568bed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[9]: (277, 284)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[9]: (277, 284)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(df),len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1062eefe-97a2-4a35-9404-1b5dd5d2aeb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "VENDORList = set(df['VENDOR'].str.strip().unique()) & set(df2['VENDOR'].str.strip().unique())\n",
    "df = df[df['VENDOR'].str.strip().isin(VENDORList)]\n",
    "df2 = df2[df2['VENDOR'].str.strip().isin(VENDORList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9aedf21-2824-40b5-a6f0-cb9846922cc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BRANDList = set(df['BRAND'].str.strip().unique()) & set(df2['BRAND'].str.strip().unique())\n",
    "df = df[df['BRAND'].str.strip().isin(BRANDList)]\n",
    "df2 = df2[df2['BRAND'].str.strip().isin(BRANDList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab1d0723-e05d-4f29-bf40-a7d5f30ad223",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRD_CATEGORYList = set(df['PRD_CATEGORY'].str.strip().unique()) & set(df2['PRD_CATEGORY'].str.strip().unique())\n",
    "df = df[df['PRD_CATEGORY'].str.strip().isin(PRD_CATEGORYList)]\n",
    "df2 = df2[df2['PRD_CATEGORY'].str.strip().isin(PRD_CATEGORYList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455ca58a-687e-4aa3-a22d-86af25fd0a7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRD_ORIGINList = set(df['PRD_ORIGIN'].str.strip().unique()) & set(df2['PRD_ORIGIN'].str.strip().unique())\n",
    "df = df[df['PRD_ORIGIN'].str.strip().isin(PRD_ORIGINList)]\n",
    "df2 = df2[df2['PRD_ORIGIN'].str.strip().isin(PRD_ORIGINList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc2622b-825e-4c77-803b-30fdeaf446b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PUBLISHERList = set(df['PUBLISHER'].str.strip().unique()) & set(df2['PUBLISHER'].str.strip().unique())\n",
    "df = df[df['PUBLISHER'].str.strip().isin(PUBLISHERList)]\n",
    "df2 = df2[df2['PUBLISHER'].str.strip().isin(PUBLISHERList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "889a2428-35e0-4b07-83af-f35080e20b7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRECATList = set(df['pred_cat'].str.strip().unique()) & set(df2['pred_cat'].str.strip().unique())\n",
    "df = df[df['pred_cat'].str.strip().isin(PRECATList)]\n",
    "df2 = df2[df2['pred_cat'].str.strip().isin(PRECATList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ba95ee-8938-46fb-b7b4-94d55521866b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df2.loc[df2['BRAND']!='S-ZONE  ']\n",
    "df2 = df2.loc[df2['VENDOR']!='HINKLER   ']\n",
    "df2 = df2.loc[df2['VENDOR']!='66-BOOKS  ']\n",
    "df2 = df2.loc[df2['VENDOR']!='CDP       ']\n",
    "df2 = df2.loc[df2['PUBLISHER']!='CDP                      ']\n",
    "df2 = df2.loc[df2['PUBLISHER']!='CAMPBELL                 ']\n",
    "df2 = df2.loc[df2['PRD_CATEGORY']!='ART  ']\n",
    "df2 = df2.loc[df2['BRAND']!='CAMPBELL']\n",
    "df2 = df2.loc[df2['BRAND']!='CDP     ']\n",
    "df = df.loc[df['VENDOR']!='RIVERSIDE ']\n",
    "df = df.loc[df['PRD_CATEGORY']!='HIS  ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8b4918e-de33-4d9b-85a3-2f8028943b78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[17]: (96, 134)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[17]: (96, 134)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(df),len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a8546d9-c4d7-4d24-a832-2c3dd5a83220",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def categorizeSales(threshold, n):\n",
    "    return 1.0 if n >= threshold else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c3f2dc-b942-4975-9aa9-594af76c699d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[19]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[19]: </div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COST</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>QTY_SALES</th>\n",
       "      <th>VENDOR</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRD_CATEGORY</th>\n",
       "      <th>PRD_ORIGIN</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>pred_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>119.90</td>\n",
       "      <td>1</td>\n",
       "      <td>HC</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>HC</td>\n",
       "      <td>pencil_box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>119.90</td>\n",
       "      <td>1</td>\n",
       "      <td>HC</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>HC</td>\n",
       "      <td>comic_book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>119.90</td>\n",
       "      <td>1</td>\n",
       "      <td>HC</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>HC</td>\n",
       "      <td>pencil_box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>F</td>\n",
       "      <td>UK</td>\n",
       "      <td>HC</td>\n",
       "      <td>packet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>107.07</td>\n",
       "      <td>389.70</td>\n",
       "      <td>17</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL</td>\n",
       "      <td>G/S</td>\n",
       "      <td>USA</td>\n",
       "      <td>SL</td>\n",
       "      <td>toyshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>21.95</td>\n",
       "      <td>79.90</td>\n",
       "      <td>10</td>\n",
       "      <td>AOL</td>\n",
       "      <td>L-BROWN</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>L-BROWN</td>\n",
       "      <td>comic_book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>21.95</td>\n",
       "      <td>79.90</td>\n",
       "      <td>7</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>SL</td>\n",
       "      <td>web_site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>35.69</td>\n",
       "      <td>129.90</td>\n",
       "      <td>16</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL</td>\n",
       "      <td>COMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>SL</td>\n",
       "      <td>envelope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>24.70</td>\n",
       "      <td>89.90</td>\n",
       "      <td>9</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL</td>\n",
       "      <td>F</td>\n",
       "      <td>USA</td>\n",
       "      <td>SL</td>\n",
       "      <td>great_white_shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>35.69</td>\n",
       "      <td>129.90</td>\n",
       "      <td>15</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL</td>\n",
       "      <td>COMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>SL</td>\n",
       "      <td>comic_book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COST</th>\n      <th>PRICE</th>\n      <th>QTY_SALES</th>\n      <th>VENDOR</th>\n      <th>BRAND</th>\n      <th>PRD_CATEGORY</th>\n      <th>PRD_ORIGIN</th>\n      <th>PUBLISHER</th>\n      <th>pred_cat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>0.00</td>\n      <td>119.90</td>\n      <td>1</td>\n      <td>HC</td>\n      <td>HARPER</td>\n      <td>F</td>\n      <td>UK</td>\n      <td>HC</td>\n      <td>pencil_box</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.00</td>\n      <td>119.90</td>\n      <td>1</td>\n      <td>HC</td>\n      <td>HARPER</td>\n      <td>F</td>\n      <td>UK</td>\n      <td>HC</td>\n      <td>comic_book</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.00</td>\n      <td>119.90</td>\n      <td>1</td>\n      <td>HC</td>\n      <td>HARPER</td>\n      <td>F</td>\n      <td>UK</td>\n      <td>HC</td>\n      <td>pencil_box</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.00</td>\n      <td>105.00</td>\n      <td>2</td>\n      <td>HC</td>\n      <td>HARPER</td>\n      <td>F</td>\n      <td>UK</td>\n      <td>HC</td>\n      <td>packet</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>107.07</td>\n      <td>389.70</td>\n      <td>17</td>\n      <td>SL</td>\n      <td>SL</td>\n      <td>G/S</td>\n      <td>USA</td>\n      <td>SL</td>\n      <td>toyshop</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>21.95</td>\n      <td>79.90</td>\n      <td>10</td>\n      <td>AOL</td>\n      <td>L-BROWN</td>\n      <td>F</td>\n      <td>USA</td>\n      <td>L-BROWN</td>\n      <td>comic_book</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>21.95</td>\n      <td>79.90</td>\n      <td>7</td>\n      <td>SL</td>\n      <td>SL</td>\n      <td>F</td>\n      <td>USA</td>\n      <td>SL</td>\n      <td>web_site</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>35.69</td>\n      <td>129.90</td>\n      <td>16</td>\n      <td>SL</td>\n      <td>SL</td>\n      <td>COMIC</td>\n      <td>USA</td>\n      <td>SL</td>\n      <td>envelope</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>24.70</td>\n      <td>89.90</td>\n      <td>9</td>\n      <td>SL</td>\n      <td>SL</td>\n      <td>F</td>\n      <td>USA</td>\n      <td>SL</td>\n      <td>great_white_shark</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>35.69</td>\n      <td>129.90</td>\n      <td>15</td>\n      <td>SL</td>\n      <td>SL</td>\n      <td>COMIC</td>\n      <td>USA</td>\n      <td>SL</td>\n      <td>comic_book</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 9 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = df[['COST','PRICE', 'QTY_SALES','VENDOR','BRAND','PRD_CATEGORY','PRD_ORIGIN','PUBLISHER','pred_cat']]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cee8ff2-1a11-442a-9f0b-8f5231e85397",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;command-2592544856645817&gt;:1: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  df3[&#39;COST&#39;] = pd.to_numeric(df[&#39;COST&#39;], errors=&#39;coerce&#39;)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;command-2592544856645817&gt;:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df3[&#39;COST&#39;] = pd.to_numeric(df[&#39;COST&#39;], errors=&#39;coerce&#39;)\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3['COST'] = pd.to_numeric(df['COST'], errors='coerce')\n",
    "df3 = df3.dropna(subset=['COST'])\n",
    "df3['COST'] = df3['COST'].astype(float)\n",
    "df3['PRICE'] = df3['PRICE'].astype(float)\n",
    "df3['QTY_SALES'] = df3['QTY_SALES'].astype(float)\n",
    "df3[\"QTY_SALES\"] = minmax_scale(df3[\"QTY_SALES\"], feature_range=(0, 1), axis=0, copy=True)\n",
    "df3 = pd.get_dummies(df3, prefix=\"cat\", \n",
    "                            columns=[\"VENDOR\",\"BRAND\",\"PRD_CATEGORY\",\"PRD_ORIGIN\",\"PUBLISHER\",\"pred_cat\"], \n",
    "                            drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51a4b44-cfa0-4347-b4ea-6d043ae8330f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define trainging data set and testing data set\n",
    "training_data, testing_data = train_test_split(df3, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38f288fc-d58d-4b31-88e8-e3fb5dca2058",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "x_data = training_data.drop(labels=['QTY_SALES'],axis=1)\n",
    "y_data = training_data['QTY_SALES'].apply(lambda x: categorizeSales(threshold, x))\n",
    "x_data_test = testing_data.drop(labels=['QTY_SALES'],axis=1)\n",
    "y_data_test = testing_data['QTY_SALES'].apply(lambda x: categorizeSales(threshold, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01554803-58c7-439b-8364-ae6acc48cd59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[23]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[23]: </div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COST</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>cat_AOL</th>\n",
       "      <th>cat_HC</th>\n",
       "      <th>cat_HC-USA</th>\n",
       "      <th>cat_MML</th>\n",
       "      <th>cat_MPS</th>\n",
       "      <th>cat_PE-USA</th>\n",
       "      <th>cat_PI</th>\n",
       "      <th>cat_RH</th>\n",
       "      <th>cat_S&amp;S</th>\n",
       "      <th>cat_SL</th>\n",
       "      <th>cat_TBS</th>\n",
       "      <th>cat_ANDREWS</th>\n",
       "      <th>cat_BBY</th>\n",
       "      <th>cat_DK(USA)</th>\n",
       "      <th>cat_EGM</th>\n",
       "      <th>cat_HARPER</th>\n",
       "      <th>cat_HC-USA</th>\n",
       "      <th>cat_L-BROWN</th>\n",
       "      <th>cat_MML</th>\n",
       "      <th>cat_PENGUIN</th>\n",
       "      <th>cat_PI</th>\n",
       "      <th>cat_PUFFIN</th>\n",
       "      <th>cat_RH</th>\n",
       "      <th>cat_S&amp;S</th>\n",
       "      <th>cat_SL</th>\n",
       "      <th>cat_SL-UK</th>\n",
       "      <th>cat_UB</th>\n",
       "      <th>cat_B.BK</th>\n",
       "      <th>cat_C-B</th>\n",
       "      <th>cat_COMIC</th>\n",
       "      <th>cat_F</th>\n",
       "      <th>cat_G/S</th>\n",
       "      <th>cat_GB</th>\n",
       "      <th>cat_L-T-F</th>\n",
       "      <th>cat_LR-1</th>\n",
       "      <th>cat_LR-2</th>\n",
       "      <th>cat_LR-3</th>\n",
       "      <th>cat_N/F</th>\n",
       "      <th>cat_PIC</th>\n",
       "      <th>cat_REF</th>\n",
       "      <th>cat_SOUND</th>\n",
       "      <th>cat_UK</th>\n",
       "      <th>cat_USA</th>\n",
       "      <th>cat_ANDREWS</th>\n",
       "      <th>cat_BLOOMSBURY</th>\n",
       "      <th>cat_DK(USA)</th>\n",
       "      <th>cat_EGM</th>\n",
       "      <th>cat_HC</th>\n",
       "      <th>cat_HC-USA</th>\n",
       "      <th>cat_L-BROWN</th>\n",
       "      <th>cat_MML-C</th>\n",
       "      <th>cat_MML-USA</th>\n",
       "      <th>cat_PENGUIN</th>\n",
       "      <th>cat_PI</th>\n",
       "      <th>cat_PUFFIN</th>\n",
       "      <th>cat_RH</th>\n",
       "      <th>cat_S&amp;S</th>\n",
       "      <th>cat_SL</th>\n",
       "      <th>cat_SL-UK</th>\n",
       "      <th>cat_UB</th>\n",
       "      <th>cat_binder</th>\n",
       "      <th>cat_book_jacket</th>\n",
       "      <th>cat_comic_book</th>\n",
       "      <th>cat_envelope</th>\n",
       "      <th>cat_great_white_shark</th>\n",
       "      <th>cat_menu</th>\n",
       "      <th>cat_packet</th>\n",
       "      <th>cat_pencil_box</th>\n",
       "      <th>cat_rubber_eraser</th>\n",
       "      <th>cat_slot</th>\n",
       "      <th>cat_toyshop</th>\n",
       "      <th>cat_web_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>52.89</td>\n",
       "      <td>269.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>16.46</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30.32</td>\n",
       "      <td>119.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>55.26</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>29.79</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.76</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.19</td>\n",
       "      <td>109.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>46.29</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>11.76</td>\n",
       "      <td>59.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>107.07</td>\n",
       "      <td>389.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 74 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COST</th>\n      <th>PRICE</th>\n      <th>cat_AOL</th>\n      <th>cat_HC</th>\n      <th>cat_HC-USA</th>\n      <th>cat_MML</th>\n      <th>cat_MPS</th>\n      <th>cat_PE-USA</th>\n      <th>cat_PI</th>\n      <th>cat_RH</th>\n      <th>cat_S&amp;S</th>\n      <th>cat_SL</th>\n      <th>cat_TBS</th>\n      <th>cat_ANDREWS</th>\n      <th>cat_BBY</th>\n      <th>cat_DK(USA)</th>\n      <th>cat_EGM</th>\n      <th>cat_HARPER</th>\n      <th>cat_HC-USA</th>\n      <th>cat_L-BROWN</th>\n      <th>cat_MML</th>\n      <th>cat_PENGUIN</th>\n      <th>cat_PI</th>\n      <th>cat_PUFFIN</th>\n      <th>cat_RH</th>\n      <th>cat_S&amp;S</th>\n      <th>cat_SL</th>\n      <th>cat_SL-UK</th>\n      <th>cat_UB</th>\n      <th>cat_B.BK</th>\n      <th>cat_C-B</th>\n      <th>cat_COMIC</th>\n      <th>cat_F</th>\n      <th>cat_G/S</th>\n      <th>cat_GB</th>\n      <th>cat_L-T-F</th>\n      <th>cat_LR-1</th>\n      <th>cat_LR-2</th>\n      <th>cat_LR-3</th>\n      <th>cat_N/F</th>\n      <th>cat_PIC</th>\n      <th>cat_REF</th>\n      <th>cat_SOUND</th>\n      <th>cat_UK</th>\n      <th>cat_USA</th>\n      <th>cat_ANDREWS</th>\n      <th>cat_BLOOMSBURY</th>\n      <th>cat_DK(USA)</th>\n      <th>cat_EGM</th>\n      <th>cat_HC</th>\n      <th>cat_HC-USA</th>\n      <th>cat_L-BROWN</th>\n      <th>cat_MML-C</th>\n      <th>cat_MML-USA</th>\n      <th>cat_PENGUIN</th>\n      <th>cat_PI</th>\n      <th>cat_PUFFIN</th>\n      <th>cat_RH</th>\n      <th>cat_S&amp;S</th>\n      <th>cat_SL</th>\n      <th>cat_SL-UK</th>\n      <th>cat_UB</th>\n      <th>cat_binder</th>\n      <th>cat_book_jacket</th>\n      <th>cat_comic_book</th>\n      <th>cat_envelope</th>\n      <th>cat_great_white_shark</th>\n      <th>cat_menu</th>\n      <th>cat_packet</th>\n      <th>cat_pencil_box</th>\n      <th>cat_rubber_eraser</th>\n      <th>cat_slot</th>\n      <th>cat_toyshop</th>\n      <th>cat_web_site</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>52.89</td>\n      <td>269.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>16.46</td>\n      <td>69.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>30.32</td>\n      <td>119.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>55.26</td>\n      <td>220.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>29.79</td>\n      <td>115.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>11.76</td>\n      <td>59.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>30.19</td>\n      <td>109.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>46.29</td>\n      <td>119.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>11.76</td>\n      <td>59.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>107.07</td>\n      <td>389.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>76 rows × 74 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c12c5f5-1657-4a8b-acf5-d675b97b023e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu',input_dim=x_data.shape[1]))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42d942dc-fd13-4fa4-b29a-3b26a680ac04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Model: &#34;sequential&#34;\n",
       "_________________________________________________________________\n",
       " Layer (type)                Output Shape              Param #   \n",
       "=================================================================\n",
       " dense (Dense)               (None, 512)               38400     \n",
       "                                                                 \n",
       " dropout (Dropout)           (None, 512)               0         \n",
       "                                                                 \n",
       " dense_1 (Dense)             (None, 256)               131328    \n",
       "                                                                 \n",
       " dropout_1 (Dropout)         (None, 256)               0         \n",
       "                                                                 \n",
       " dense_2 (Dense)             (None, 1)                 257       \n",
       "                                                                 \n",
       "=================================================================\n",
       "Total params: 169,985\n",
       "Trainable params: 169,985\n",
       "Non-trainable params: 0\n",
       "_________________________________________________________________\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Model: &#34;sequential&#34;\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 512)               38400     \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 256)               131328    \n                                                                 \n dropout_1 (Dropout)         (None, 256)               0         \n                                                                 \n dense_2 (Dense)             (None, 1)                 257       \n                                                                 \n=================================================================\nTotal params: 169,985\nTrainable params: 169,985\nNon-trainable params: 0\n_________________________________________________________________\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2ae36ce-2e43-4861-ab7b-561a58c8a925",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[26]: (76, 76)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[26]: (76, 76)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(x_data),len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "728951aa-e624-4c3e-9935-5d101949b1ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Epoch 1/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 1s - loss: 2.9229 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 1s 121ms/step - loss: 1.5298 - accuracy: 0.8158\n",
       "Epoch 2/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 2.0402 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 1.6041 - accuracy: 0.9605\n",
       "Epoch 3/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.6296 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 1.8568 - accuracy: 0.9605\n",
       "Epoch 4/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.2435 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 1.6765 - accuracy: 0.9605\n",
       "Epoch 5/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.0166 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 1.1980 - accuracy: 0.9605\n",
       "Epoch 6/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.9144 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.9605\n",
       "Epoch 7/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3627 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 0.7406 - accuracy: 0.8553\n",
       "Epoch 8/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8088 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.8618 - accuracy: 0.7895\n",
       "Epoch 9/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.7175 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.9211\n",
       "Epoch 10/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3333 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.9605\n",
       "Epoch 11/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.9474\n",
       "Epoch 12/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.9605\n",
       "Epoch 13/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0589 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9605\n",
       "Epoch 14/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.1293 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.8816\n",
       "Epoch 15/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8709 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.8947\n",
       "Epoch 16/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1548 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.9474\n",
       "Epoch 17/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.9605\n",
       "Epoch 18/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8714 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.9079\n",
       "Epoch 19/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.7399 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.9474\n",
       "Epoch 20/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1527 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9474\n",
       "Epoch 21/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.2724 - accuracy: 0.9211\n",
       "Epoch 22/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4052 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.9211\n",
       "Epoch 23/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.6898 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.9474\n",
       "Epoch 24/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3862 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.9605\n",
       "Epoch 25/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5474 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2458 - accuracy: 0.9605\n",
       "Epoch 26/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5935 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.9605\n",
       "Epoch 27/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9605\n",
       "Epoch 28/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9737\n",
       "Epoch 29/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4133 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.9079\n",
       "Epoch 30/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1068 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.8947\n",
       "Epoch 31/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3368 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9737\n",
       "Epoch 32/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.9605\n",
       "Epoch 33/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5989 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.9605\n",
       "Epoch 34/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9474\n",
       "Epoch 35/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.9737\n",
       "Epoch 36/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2826 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9605\n",
       "Epoch 37/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5514 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9474\n",
       "Epoch 38/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1576 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9605\n",
       "Epoch 39/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2523 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.9474\n",
       "Epoch 40/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2844 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.9211\n",
       "Epoch 41/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0768 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9474\n",
       "Epoch 42/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9737\n",
       "Epoch 43/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.9214 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.9605\n",
       "Epoch 44/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.6515 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.9605\n",
       "Epoch 45/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9474\n",
       "Epoch 46/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0317 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.3402 - accuracy: 0.9605\n",
       "Epoch 47/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8553\n",
       "Epoch 48/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3974 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.2696 - accuracy: 0.9079\n",
       "Epoch 49/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4897 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2101 - accuracy: 0.9737\n",
       "Epoch 50/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3896 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.9605\n",
       "Epoch 51/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2990 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9605\n",
       "Epoch 52/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5086 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9737\n",
       "Epoch 53/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1215 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.2537 - accuracy: 0.9342\n",
       "Epoch 54/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0683 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8947\n",
       "Epoch 55/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1164 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9474\n",
       "Epoch 56/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4206 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.9605\n",
       "Epoch 57/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9737\n",
       "Epoch 58/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9737\n",
       "Epoch 59/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0954 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.9605\n",
       "Epoch 60/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0599 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9605\n",
       "Epoch 61/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3826 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8816\n",
       "Epoch 62/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1208 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.9474\n",
       "Epoch 63/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3439 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9737\n",
       "Epoch 64/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9737\n",
       "Epoch 65/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0335 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.9605\n",
       "Epoch 66/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9868\n",
       "Epoch 67/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9474\n",
       "Epoch 68/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9605\n",
       "Epoch 69/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3729 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9737\n",
       "Epoch 70/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0553 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9737\n",
       "Epoch 71/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0339 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9605\n",
       "Epoch 72/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0335 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9737\n",
       "Epoch 73/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9737\n",
       "Epoch 74/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2881 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1999 - accuracy: 0.9737\n",
       "Epoch 75/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4462 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9605\n",
       "Epoch 76/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.9868\n",
       "Epoch 77/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1475 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9605\n",
       "Epoch 78/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1057 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9868\n",
       "Epoch 79/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1235 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9211\n",
       "Epoch 80/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2659 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9605\n",
       "Epoch 81/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9737\n",
       "Epoch 82/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0562 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9474\n",
       "Epoch 83/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9737\n",
       "Epoch 84/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0569 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9737\n",
       "Epoch 85/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2471 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9868\n",
       "Epoch 86/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4080 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.9211\n",
       "Epoch 87/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9868\n",
       "Epoch 88/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3200 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9868\n",
       "Epoch 89/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9605\n",
       "Epoch 90/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0511 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9868\n",
       "Epoch 91/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3128 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1523 - accuracy: 0.9868\n",
       "Epoch 92/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2120 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9737\n",
       "Epoch 93/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0460 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9868\n",
       "Epoch 94/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9868\n",
       "Epoch 95/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2027 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9605\n",
       "Epoch 96/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1089 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9737\n",
       "Epoch 97/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0301 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9868\n",
       "Epoch 98/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9868\n",
       "Epoch 99/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2792 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.9737\n",
       "Epoch 100/100\n",
       "\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2675 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9605\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpfksl1qmx/model/data/model/assets\n",
       "Out[27]: &lt;keras.callbacks.History at 0x7ff12874bdc0&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Epoch 1/100\n\r1/3 [=========&gt;....................] - ETA: 1s - loss: 2.9229 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 1s 121ms/step - loss: 1.5298 - accuracy: 0.8158\nEpoch 2/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 2.0402 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 1.6041 - accuracy: 0.9605\nEpoch 3/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.6296 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 1.8568 - accuracy: 0.9605\nEpoch 4/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.2435 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 1.6765 - accuracy: 0.9605\nEpoch 5/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.0166 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 1.1980 - accuracy: 0.9605\nEpoch 6/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.9144 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.9605\nEpoch 7/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3627 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 0.7406 - accuracy: 0.8553\nEpoch 8/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8088 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.8618 - accuracy: 0.7895\nEpoch 9/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.7175 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.9211\nEpoch 10/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3333 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.9605\nEpoch 11/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0125 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.9474\nEpoch 12/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.9605\nEpoch 13/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0589 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9605\nEpoch 14/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 1.1293 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.8816\nEpoch 15/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8709 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.8947\nEpoch 16/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1548 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.9474\nEpoch 17/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.9605\nEpoch 18/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.8714 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.9079\nEpoch 19/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.7399 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.9474\nEpoch 20/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1527 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9474\nEpoch 21/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.2724 - accuracy: 0.9211\nEpoch 22/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4052 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.9211\nEpoch 23/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.6898 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.9474\nEpoch 24/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3862 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.9605\nEpoch 25/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5474 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2458 - accuracy: 0.9605\nEpoch 26/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5935 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.9605\nEpoch 27/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9605\nEpoch 28/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9737\nEpoch 29/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4133 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.9079\nEpoch 30/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1068 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.8947\nEpoch 31/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3368 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9737\nEpoch 32/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.9605\nEpoch 33/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5989 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.9605\nEpoch 34/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9474\nEpoch 35/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.9737\nEpoch 36/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2826 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9605\nEpoch 37/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5514 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9474\nEpoch 38/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1576 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9605\nEpoch 39/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2523 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.9474\nEpoch 40/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2844 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.9211\nEpoch 41/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0768 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1637 - accuracy: 0.9474\nEpoch 42/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9737\nEpoch 43/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.9214 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.9605\nEpoch 44/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.6515 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.9605\nEpoch 45/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9474\nEpoch 46/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0317 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.3402 - accuracy: 0.9605\nEpoch 47/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8553\nEpoch 48/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3974 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.2696 - accuracy: 0.9079\nEpoch 49/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4897 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2101 - accuracy: 0.9737\nEpoch 50/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3896 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.9605\nEpoch 51/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2990 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9605\nEpoch 52/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.5086 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9737\nEpoch 53/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1215 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.2537 - accuracy: 0.9342\nEpoch 54/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0683 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8947\nEpoch 55/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1164 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9474\nEpoch 56/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4206 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.9605\nEpoch 57/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9737\nEpoch 58/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9737\nEpoch 59/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0954 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.9605\nEpoch 60/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0599 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1409 - accuracy: 0.9605\nEpoch 61/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3826 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8816\nEpoch 62/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1208 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.9474\nEpoch 63/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3439 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.9737\nEpoch 64/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0811 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9737\nEpoch 65/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0335 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.9605\nEpoch 66/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0120 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9868\nEpoch 67/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9474\nEpoch 68/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1854 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9605\nEpoch 69/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3729 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9737\nEpoch 70/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0553 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9737\nEpoch 71/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0339 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9605\nEpoch 72/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0335 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9737\nEpoch 73/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9737\nEpoch 74/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2881 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1999 - accuracy: 0.9737\nEpoch 75/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4462 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9605\nEpoch 76/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.9868\nEpoch 77/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1475 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9605\nEpoch 78/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1057 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9868\nEpoch 79/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1235 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9211\nEpoch 80/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2659 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9605\nEpoch 81/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9737\nEpoch 82/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0562 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9474\nEpoch 83/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9737\nEpoch 84/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0569 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9737\nEpoch 85/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2471 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9868\nEpoch 86/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.4080 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.9211\nEpoch 87/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9868\nEpoch 88/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3200 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9868\nEpoch 89/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9605\nEpoch 90/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0511 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9868\nEpoch 91/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.3128 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.1523 - accuracy: 0.9868\nEpoch 92/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2120 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.1829 - accuracy: 0.9737\nEpoch 93/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0460 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9868\nEpoch 94/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9868\nEpoch 95/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2027 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9605\nEpoch 96/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1089 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9737\nEpoch 97/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.0301 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9868\nEpoch 98/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.1625 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9868\nEpoch 99/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2792 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.9737\nEpoch 100/100\n\r1/3 [=========&gt;....................] - ETA: 0s - loss: 0.2675 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 0s 5ms/step - loss: 0.1644 - accuracy: 0.9605\nINFO:tensorflow:Assets written to: /tmp/tmpfksl1qmx/model/data/model/assets\nOut[27]: &lt;keras.callbacks.History at 0x7ff12874bdc0&gt;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(x=x_data, y=y_data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4769339-bc34-431f-bbff-96bafc1c107e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[28]: (20, 20)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[28]: (20, 20)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(x_data_test) , len(y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2eb65b-1f44-410d-9f4d-53a17f562588",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">\r1/1 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 169ms/step - loss: 0.0110 - accuracy: 1.0000\n",
       "Test score: 0.010982653126120567\n",
       "Test accuracy: 1.0\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">\r1/1 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 169ms/step - loss: 0.0110 - accuracy: 1.0000\nTest score: 0.010982653126120567\nTest accuracy: 1.0\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_data_test, y_data_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523bf9d6-e1d7-44a7-b650-a6ea8c3d6a86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;command-2592544856645827&gt;:2: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  df4[&#39;COST&#39;] = pd.to_numeric(df2[&#39;COST&#39;], errors=&#39;coerce&#39;)\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;command-2592544856645827&gt;:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df4[&#39;COST&#39;] = pd.to_numeric(df2[&#39;COST&#39;], errors=&#39;coerce&#39;)\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4 = df2[['COST','PRICE','VENDOR','BRAND','PRD_CATEGORY','PRD_ORIGIN','PUBLISHER','QTY_SALES','pred_cat']]\n",
    "df4['COST'] = pd.to_numeric(df2['COST'], errors='coerce')\n",
    "df4 = df4.dropna(subset=['COST'])\n",
    "df4['COST'] = df4['COST'].astype(float)\n",
    "df4['PRICE'] = df4['PRICE'].astype(float)\n",
    "df4 = pd.get_dummies(df4, prefix=\"cat\", columns=[\"VENDOR\",\"BRAND\",\"PRD_CATEGORY\",\"PRD_ORIGIN\",\"PUBLISHER\",\"pred_cat\"], drop_first=False)\n",
    "df4['QTY_SALES'] = minmax_scale(df4[\"QTY_SALES\"], feature_range=(0, 1), axis=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10aeec1f-8a87-4998-b08c-2667d28601f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df4['QTY_SALES'].apply(lambda x: categorizeSales(threshold, x))\n",
    "x = df4.loc[:, ~df4.columns.isin(['QTY_SALES'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a754d3c9-bca1-41dd-ac37-7e1a62665109",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.2940 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9552\n",
       "Test score: 0.2960050702095032\n",
       "Test accuracy: 0.9552238583564758\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.2940 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9552\nTest score: 0.2960050702095032\nTest accuracy: 0.9552238583564758\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, acc = model.evaluate(x, y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a6ac66-613b-4428-b60f-fc8e977a75c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(x))\n",
    "y_pred = y_pred.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5befd39d-17b7-49b8-a36b-19dc925597da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.96      1.00      0.98       128\n",
       "     class 1       0.00      0.00      0.00         6\n",
       "\n",
       "    accuracy                           0.96       134\n",
       "   macro avg       0.48      0.50      0.49       134\n",
       "weighted avg       0.91      0.96      0.93       134\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n              precision    recall  f1-score   support\n\n     class 0       0.96      1.00      0.98       128\n     class 1       0.00      0.00      0.00         6\n\n    accuracy                           0.96       134\n   macro avg       0.48      0.50      0.49       134\nweighted avg       0.91      0.96      0.93       134\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ec26e6e-d648-4efa-b099-d5cffd73c304",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def runModel(df_train, df_test, model ,threshold,accuracy):\n",
    "    x_train = df_train.drop(labels=['QTY_SALES'],axis=1)\n",
    "    y_train = df_train[\"QTY_SALES\"].apply(lambda x: categorizeSales(threshold, x))\n",
    "\n",
    "    x_test = df_test.drop(labels=['QTY_SALES'],axis=1)\n",
    "    y_test = df_test[\"QTY_SALES\"].apply(lambda x: categorizeSales(threshold, x))\n",
    "\n",
    "    model.fit(x=x_train, y=y_train, epochs=100,verbose=0)\n",
    "\n",
    "    score, acc = model.evaluate(x_test, y_test)\n",
    "    print(\"Threshold: {}\".format(str(threshold)))\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "\n",
    "    y_train_pred = np.round(model.predict(x_train))\n",
    "    y_train_pred = y_train_pred.astype(\"float64\")\n",
    "    print(classification_report(y_train, y_train_pred, target_names=target_names))\n",
    "\n",
    "    y_pred = np.round(model.predict(x_test))\n",
    "    y_pred = y_pred.astype(\"float64\")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    accuracy= accuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39608d8d-c32e-4cdd-9834-c367efa53f48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">INFO:tensorflow:Assets written to: /tmp/tmpgz6r_4nf/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.3839 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8881\n",
       "Threshold: 0.01\n",
       "Test score: 0.41809219121932983\n",
       "Test accuracy: 0.888059675693512\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.80      0.36      0.50        11\n",
       "     class 1       0.92      0.99      0.95        85\n",
       "\n",
       "    accuracy                           0.92        96\n",
       "   macro avg       0.86      0.68      0.73        96\n",
       "weighted avg       0.91      0.92      0.90        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       1.00      0.06      0.12        16\n",
       "     class 1       0.89      1.00      0.94       118\n",
       "\n",
       "    accuracy                           0.89       134\n",
       "   macro avg       0.94      0.53      0.53       134\n",
       "weighted avg       0.90      0.89      0.84       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpl6w250y4/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.6808 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6716\n",
       "Threshold: 0.02\n",
       "Test score: 0.6190083026885986\n",
       "Test accuracy: 0.6716417670249939\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.75      0.64      0.69        28\n",
       "     class 1       0.86      0.91      0.89        68\n",
       "\n",
       "    accuracy                           0.83        96\n",
       "   macro avg       0.81      0.78      0.79        96\n",
       "weighted avg       0.83      0.83      0.83        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.47      0.16      0.24        43\n",
       "     class 1       0.70      0.91      0.79        91\n",
       "\n",
       "    accuracy                           0.67       134\n",
       "   macro avg       0.58      0.54      0.52       134\n",
       "weighted avg       0.62      0.67      0.61       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpgyxqe9ss/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.9137 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6343\n",
       "Threshold: 0.03\n",
       "Test score: 0.7146362662315369\n",
       "Test accuracy: 0.6343283653259277\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.97      0.69      0.80        51\n",
       "     class 1       0.73      0.98      0.84        45\n",
       "\n",
       "    accuracy                           0.82        96\n",
       "   macro avg       0.85      0.83      0.82        96\n",
       "weighted avg       0.86      0.82      0.82        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.62      0.59      0.61        64\n",
       "     class 1       0.64      0.67      0.66        70\n",
       "\n",
       "    accuracy                           0.63       134\n",
       "   macro avg       0.63      0.63      0.63       134\n",
       "weighted avg       0.63      0.63      0.63       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpcfcitv1p/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.5213 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.6045\n",
       "Threshold: 0.04\n",
       "Test score: 1.0153748989105225\n",
       "Test accuracy: 0.60447758436203\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.96      0.78      0.86        65\n",
       "     class 1       0.67      0.94      0.78        31\n",
       "\n",
       "    accuracy                           0.83        96\n",
       "   macro avg       0.82      0.86      0.82        96\n",
       "weighted avg       0.87      0.83      0.84        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.67      0.68      0.67        81\n",
       "     class 1       0.50      0.49      0.50        53\n",
       "\n",
       "    accuracy                           0.60       134\n",
       "   macro avg       0.59      0.58      0.59       134\n",
       "weighted avg       0.60      0.60      0.60       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmplzj2vu2v/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.1119 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.6940\n",
       "Threshold: 0.05\n",
       "Test score: 0.9867563843727112\n",
       "Test accuracy: 0.6940298676490784\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.96      0.93      0.94        72\n",
       "     class 1       0.81      0.88      0.84        24\n",
       "\n",
       "    accuracy                           0.92        96\n",
       "   macro avg       0.88      0.90      0.89        96\n",
       "weighted avg       0.92      0.92      0.92        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.74      0.89      0.81        96\n",
       "     class 1       0.42      0.21      0.28        38\n",
       "\n",
       "    accuracy                           0.69       134\n",
       "   macro avg       0.58      0.55      0.54       134\n",
       "weighted avg       0.65      0.69      0.66       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmp8quxbp3g/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.2715 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.9590 - accuracy: 0.8358\n",
       "Threshold: 0.06\n",
       "Test score: 0.9590452909469604\n",
       "Test accuracy: 0.8358209133148193\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.96      0.96      0.96        78\n",
       "     class 1       0.83      0.83      0.83        18\n",
       "\n",
       "    accuracy                           0.94        96\n",
       "   macro avg       0.90      0.90      0.90        96\n",
       "weighted avg       0.94      0.94      0.94        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.87      0.95      0.91       111\n",
       "     class 1       0.54      0.30      0.39        23\n",
       "\n",
       "    accuracy                           0.84       134\n",
       "   macro avg       0.70      0.63      0.65       134\n",
       "weighted avg       0.81      0.84      0.82       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpe8bb25tx/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.3178 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.8582\n",
       "Threshold: 0.07\n",
       "Test score: 1.0880982875823975\n",
       "Test accuracy: 0.858208954334259\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.99      0.94      0.96        83\n",
       "     class 1       0.71      0.92      0.80        13\n",
       "\n",
       "    accuracy                           0.94        96\n",
       "   macro avg       0.85      0.93      0.88        96\n",
       "weighted avg       0.95      0.94      0.94        96\n",
       "\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.88      0.96      0.92       113\n",
       "     class 1       0.60      0.29      0.39        21\n",
       "\n",
       "    accuracy                           0.86       134\n",
       "   macro avg       0.74      0.63      0.65       134\n",
       "weighted avg       0.84      0.86      0.84       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpxvbgeu_p/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.9532 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0621 - accuracy: 0.8881\n",
       "Threshold: 0.08\n",
       "Test score: 1.0620628595352173\n",
       "Test accuracy: 0.888059675693512\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.94      1.00      0.97        87\n",
       "     class 1       1.00      0.33      0.50         9\n",
       "\n",
       "    accuracy                           0.94        96\n",
       "   macro avg       0.97      0.67      0.73        96\n",
       "weighted avg       0.94      0.94      0.92        96\n",
       "\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.89      1.00      0.94       119\n",
       "     class 1       0.00      0.00      0.00        15\n",
       "\n",
       "    accuracy                           0.89       134\n",
       "   macro avg       0.44      0.50      0.47       134\n",
       "weighted avg       0.79      0.89      0.84       134\n",
       "\n",
       "INFO:tensorflow:Assets written to: /tmp/tmpqq396aog/model/data/model/assets\n",
       "\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.1523 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.2559 - accuracy: 0.8881\n",
       "Threshold: 0.09\n",
       "Test score: 1.2559478282928467\n",
       "Test accuracy: 0.888059675693512\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.97      1.00      0.98        89\n",
       "     class 1       1.00      0.57      0.73         7\n",
       "\n",
       "    accuracy                           0.97        96\n",
       "   macro avg       0.98      0.79      0.86        96\n",
       "weighted avg       0.97      0.97      0.96        96\n",
       "\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
       "  _warn_prf(average, modifier, msg_start, len(result))\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     class 0       0.89      1.00      0.94       119\n",
       "     class 1       0.00      0.00      0.00        15\n",
       "\n",
       "    accuracy                           0.89       134\n",
       "   macro avg       0.44      0.50      0.47       134\n",
       "weighted avg       0.79      0.89      0.84       134\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">INFO:tensorflow:Assets written to: /tmp/tmpgz6r_4nf/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.3839 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8881\nThreshold: 0.01\nTest score: 0.41809219121932983\nTest accuracy: 0.888059675693512\n              precision    recall  f1-score   support\n\n     class 0       0.80      0.36      0.50        11\n     class 1       0.92      0.99      0.95        85\n\n    accuracy                           0.92        96\n   macro avg       0.86      0.68      0.73        96\nweighted avg       0.91      0.92      0.90        96\n\n              precision    recall  f1-score   support\n\n     class 0       1.00      0.06      0.12        16\n     class 1       0.89      1.00      0.94       118\n\n    accuracy                           0.89       134\n   macro avg       0.94      0.53      0.53       134\nweighted avg       0.90      0.89      0.84       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpl6w250y4/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.6808 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6716\nThreshold: 0.02\nTest score: 0.6190083026885986\nTest accuracy: 0.6716417670249939\n              precision    recall  f1-score   support\n\n     class 0       0.75      0.64      0.69        28\n     class 1       0.86      0.91      0.89        68\n\n    accuracy                           0.83        96\n   macro avg       0.81      0.78      0.79        96\nweighted avg       0.83      0.83      0.83        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.47      0.16      0.24        43\n     class 1       0.70      0.91      0.79        91\n\n    accuracy                           0.67       134\n   macro avg       0.58      0.54      0.52       134\nweighted avg       0.62      0.67      0.61       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpgyxqe9ss/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.9137 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.6343\nThreshold: 0.03\nTest score: 0.7146362662315369\nTest accuracy: 0.6343283653259277\n              precision    recall  f1-score   support\n\n     class 0       0.97      0.69      0.80        51\n     class 1       0.73      0.98      0.84        45\n\n    accuracy                           0.82        96\n   macro avg       0.85      0.83      0.82        96\nweighted avg       0.86      0.82      0.82        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.62      0.59      0.61        64\n     class 1       0.64      0.67      0.66        70\n\n    accuracy                           0.63       134\n   macro avg       0.63      0.63      0.63       134\nweighted avg       0.63      0.63      0.63       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpcfcitv1p/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.5213 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0154 - accuracy: 0.6045\nThreshold: 0.04\nTest score: 1.0153748989105225\nTest accuracy: 0.60447758436203\n              precision    recall  f1-score   support\n\n     class 0       0.96      0.78      0.86        65\n     class 1       0.67      0.94      0.78        31\n\n    accuracy                           0.83        96\n   macro avg       0.82      0.86      0.82        96\nweighted avg       0.87      0.83      0.84        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.67      0.68      0.67        81\n     class 1       0.50      0.49      0.50        53\n\n    accuracy                           0.60       134\n   macro avg       0.59      0.58      0.59       134\nweighted avg       0.60      0.60      0.60       134\n\nINFO:tensorflow:Assets written to: /tmp/tmplzj2vu2v/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.1119 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.6940\nThreshold: 0.05\nTest score: 0.9867563843727112\nTest accuracy: 0.6940298676490784\n              precision    recall  f1-score   support\n\n     class 0       0.96      0.93      0.94        72\n     class 1       0.81      0.88      0.84        24\n\n    accuracy                           0.92        96\n   macro avg       0.88      0.90      0.89        96\nweighted avg       0.92      0.92      0.92        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.74      0.89      0.81        96\n     class 1       0.42      0.21      0.28        38\n\n    accuracy                           0.69       134\n   macro avg       0.58      0.55      0.54       134\nweighted avg       0.65      0.69      0.66       134\n\nINFO:tensorflow:Assets written to: /tmp/tmp8quxbp3g/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.2715 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 0.9590 - accuracy: 0.8358\nThreshold: 0.06\nTest score: 0.9590452909469604\nTest accuracy: 0.8358209133148193\n              precision    recall  f1-score   support\n\n     class 0       0.96      0.96      0.96        78\n     class 1       0.83      0.83      0.83        18\n\n    accuracy                           0.94        96\n   macro avg       0.90      0.90      0.90        96\nweighted avg       0.94      0.94      0.94        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.87      0.95      0.91       111\n     class 1       0.54      0.30      0.39        23\n\n    accuracy                           0.84       134\n   macro avg       0.70      0.63      0.65       134\nweighted avg       0.81      0.84      0.82       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpe8bb25tx/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.3178 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.8582\nThreshold: 0.07\nTest score: 1.0880982875823975\nTest accuracy: 0.858208954334259\n              precision    recall  f1-score   support\n\n     class 0       0.99      0.94      0.96        83\n     class 1       0.71      0.92      0.80        13\n\n    accuracy                           0.94        96\n   macro avg       0.85      0.93      0.88        96\nweighted avg       0.95      0.94      0.94        96\n\n              precision    recall  f1-score   support\n\n     class 0       0.88      0.96      0.92       113\n     class 1       0.60      0.29      0.39        21\n\n    accuracy                           0.86       134\n   macro avg       0.74      0.63      0.65       134\nweighted avg       0.84      0.86      0.84       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpxvbgeu_p/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 0.9532 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.0621 - accuracy: 0.8881\nThreshold: 0.08\nTest score: 1.0620628595352173\nTest accuracy: 0.888059675693512\n              precision    recall  f1-score   support\n\n     class 0       0.94      1.00      0.97        87\n     class 1       1.00      0.33      0.50         9\n\n    accuracy                           0.94        96\n   macro avg       0.97      0.67      0.73        96\nweighted avg       0.94      0.94      0.92        96\n\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n              precision    recall  f1-score   support\n\n     class 0       0.89      1.00      0.94       119\n     class 1       0.00      0.00      0.00        15\n\n    accuracy                           0.89       134\n   macro avg       0.44      0.50      0.47       134\nweighted avg       0.79      0.89      0.84       134\n\nINFO:tensorflow:Assets written to: /tmp/tmpqq396aog/model/data/model/assets\n\r1/5 [=====&gt;........................] - ETA: 0s - loss: 1.1523 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 0s 2ms/step - loss: 1.2559 - accuracy: 0.8881\nThreshold: 0.09\nTest score: 1.2559478282928467\nTest accuracy: 0.888059675693512\n              precision    recall  f1-score   support\n\n     class 0       0.97      1.00      0.98        89\n     class 1       1.00      0.57      0.73         7\n\n    accuracy                           0.97        96\n   macro avg       0.98      0.79      0.86        96\nweighted avg       0.97      0.97      0.96        96\n\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n              precision    recall  f1-score   support\n\n     class 0       0.89      1.00      0.94       119\n     class 1       0.00      0.00      0.00        15\n\n    accuracy                           0.89       134\n   macro avg       0.44      0.50      0.47       134\nweighted avg       0.79      0.89      0.84       134\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = []\n",
    "for t in range(1, 10):\n",
    "    threshold = t/100\n",
    "    runModel(df3, df4,model,threshold,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9ab878-63f9-4b91-befe-eb89f9e5a55b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">0.01\n",
       "Counter({1.0: 85, 0.0: 11})\n",
       "0.02\n",
       "Counter({1.0: 68, 0.0: 28})\n",
       "0.03\n",
       "Counter({0.0: 51, 1.0: 45})\n",
       "0.04\n",
       "Counter({0.0: 65, 1.0: 31})\n",
       "0.05\n",
       "Counter({0.0: 72, 1.0: 24})\n",
       "0.06\n",
       "Counter({0.0: 78, 1.0: 18})\n",
       "0.07\n",
       "Counter({0.0: 83, 1.0: 13})\n",
       "0.08\n",
       "Counter({0.0: 87, 1.0: 9})\n",
       "0.09\n",
       "Counter({0.0: 89, 1.0: 7})\n",
       "0.1\n",
       "Counter({0.0: 90, 1.0: 6})\n",
       "0.11\n",
       "Counter({0.0: 92, 1.0: 4})\n",
       "0.12\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.13\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.14\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.15\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.16\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.17\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.18\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.19\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.2\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.21\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.22\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.23\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.24\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.25\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.26\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.27\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.28\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "0.29\n",
       "Counter({0.0: 93, 1.0: 3})\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">0.01\nCounter({1.0: 85, 0.0: 11})\n0.02\nCounter({1.0: 68, 0.0: 28})\n0.03\nCounter({0.0: 51, 1.0: 45})\n0.04\nCounter({0.0: 65, 1.0: 31})\n0.05\nCounter({0.0: 72, 1.0: 24})\n0.06\nCounter({0.0: 78, 1.0: 18})\n0.07\nCounter({0.0: 83, 1.0: 13})\n0.08\nCounter({0.0: 87, 1.0: 9})\n0.09\nCounter({0.0: 89, 1.0: 7})\n0.1\nCounter({0.0: 90, 1.0: 6})\n0.11\nCounter({0.0: 92, 1.0: 4})\n0.12\nCounter({0.0: 93, 1.0: 3})\n0.13\nCounter({0.0: 93, 1.0: 3})\n0.14\nCounter({0.0: 93, 1.0: 3})\n0.15\nCounter({0.0: 93, 1.0: 3})\n0.16\nCounter({0.0: 93, 1.0: 3})\n0.17\nCounter({0.0: 93, 1.0: 3})\n0.18\nCounter({0.0: 93, 1.0: 3})\n0.19\nCounter({0.0: 93, 1.0: 3})\n0.2\nCounter({0.0: 93, 1.0: 3})\n0.21\nCounter({0.0: 93, 1.0: 3})\n0.22\nCounter({0.0: 93, 1.0: 3})\n0.23\nCounter({0.0: 93, 1.0: 3})\n0.24\nCounter({0.0: 93, 1.0: 3})\n0.25\nCounter({0.0: 93, 1.0: 3})\n0.26\nCounter({0.0: 93, 1.0: 3})\n0.27\nCounter({0.0: 93, 1.0: 3})\n0.28\nCounter({0.0: 93, 1.0: 3})\n0.29\nCounter({0.0: 93, 1.0: 3})\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in range(1, 30):\n",
    "    threshold = t/100\n",
    "    temp = df3[\"QTY_SALES\"].apply(lambda x: categorizeSales(threshold, x))\n",
    "    print(threshold)\n",
    "    print(Counter(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88ff699b-9734-4452-b3b3-faefe1ae37d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[127]: [0.888059675693512,\n",
       " 0.6791045069694519,\n",
       " 0.641791045665741,\n",
       " 0.60447758436203,\n",
       " 0.6865671873092651,\n",
       " 0.8358209133148193,\n",
       " 0.8507462739944458,\n",
       " 0.8805969953536987,\n",
       " 0.8805969953536987,\n",
       " 0.9029850959777832,\n",
       " 0.9253731369972229,\n",
       " 0.9477611780166626,\n",
       " 0.9477611780166626,\n",
       " 0.9477611780166626,\n",
       " 0.9477611780166626,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758,\n",
       " 0.9552238583564758]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[127]: [0.888059675693512,\n 0.6791045069694519,\n 0.641791045665741,\n 0.60447758436203,\n 0.6865671873092651,\n 0.8358209133148193,\n 0.8507462739944458,\n 0.8805969953536987,\n 0.8805969953536987,\n 0.9029850959777832,\n 0.9253731369972229,\n 0.9477611780166626,\n 0.9477611780166626,\n 0.9477611780166626,\n 0.9477611780166626,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758,\n 0.9552238583564758]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "combined_model_binary",
   "notebookOrigID": 2592544856645806,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
